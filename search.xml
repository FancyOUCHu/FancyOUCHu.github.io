<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Kriging 模型</title>
      <link href="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"/>
      <url>/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p>最近写毕业论文用到Kriging模型，经过一周的摸索，对其有一定的了解，遂作此笔记。<br>接下来我将从一个萌新的角度逐步带你揭开kriging模型神秘的面纱！</p><h1 id="初识kriging-模型"><a href="#初识kriging-模型" class="headerlink" title="初识kriging 模型"></a>初识kriging 模型</h1><p>一开始接触到这个名词，大家较多的会看看B站上有没有相关教程，由此映入眼帘的就是<a href="https://space.bilibili.com/6676614">猪星人</a>这位up主的视频<sup><a href="#fn_1" id="reffn_1">1</a></sup>，从那里大家就会发现kriging有现成的matlab工具箱<sup><a href="#fn_2" id="reffn_2">2</a></sup>，如下所示：<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/kriging模型工具箱.png" alt="Kriging模型工具箱"></p><p>而且工具箱也提供了几个例子，简单好上手，如<a href="https://blog.csdn.net/zhwzhaowei/article/details/114303882">CSDN上那篇博客</a>介绍。(见下图)<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/kriging工具箱自带例子.png" alt="dace工具箱例子"><br>于是大家兴奋不已，如获珍宝，难道到这就结束了？噩梦才刚开始！</p><p>紧接着，大家就会像，Kriging模型理论是啥，毕竟大家论文前面总要凑字数的嘛😁😁😁</p><p>于是你就会看到上述CSDN上博客写着的教程：</p><blockquote><p>1）参考工具箱中的dace文档<sup><a href="#fn_5" id="reffn_5">5</a></sup><br>2）<a href="https://xg1990.com/blog/archives/222">https://xg1990.com/blog/archives/222</a></p></blockquote><p>显然，对于dace自带的说明书，全英文，我们直呼不能接受！而选项2）,xg老师那篇文章<sup><a href="#fn_3" id="reffn_3">3</a></sup>，点进去一看，中文，哎，兴趣就来了。</p><blockquote><p>这里我推荐你一定要把xg1990大佬的这篇文章<strong>认真研读一遍</strong>，这篇文章算是我接触过的最易理解的关于kriging模型的介绍了！</p></blockquote><div class="pdf-container" data-target="克里金(Kriging)插值的原理与公式推导-xg1990.pdf" data-height="800px"></div><blockquote><p>pdf不显示的话刷新一下就好了！</p></blockquote><p>文中推导需要用到的一些概率统计的基本公式，这里总结一下：</p><script type="math/tex; mode=display">VarX = E\left[ { { {\left( {X - \mu } \right)}^2} } \right]</script><script type="math/tex; mode=display">\mu  = E\left( X \right)</script>$$Cov\left( {X,Y} \right) = E\left[ {\left( {X - E\left( X \right)} \right)\left( {Y - E\left( Y \right)} \right)} \right] = E\left( {XY} \right) - E\left( X \right)E\left( Y \right)$$$$Var\left( X \right) = Cov\left( {X,X} \right) = E\left( {{X^2}} \right) - {E^2}\left( X \right)$$$$Var\left( {X - Y} \right) = E\left[ {{{\left( {\left( {X - Y} \right) - E\left( {X - Y} \right)} \right)}^2}} \right] = Var\left( X \right) + Var\left( Y \right) - 2Cov\left( {X,Y} \right)$$$${\left( {\sum\limits_{i = 1}^n {{x_i}} } \right)^2} = \sum\limits_{i = 1}^n {\sum\limits_{j = 1}^n {\left( {{x_i}{x_j}} \right)} } $$$$Var\left( {\sum\limits_{i = 1}^n {{X_i}} } \right) = E\left[ {{{\left( {\sum\limits_{i = 1}^n {\left( {{X_i} - {\mu _i}} \right)} } \right)}^2}} \right] = \sum\limits_{i = 1}^n {\sum\limits_{j = 1}^n {E\left[ {\left( {{X_i} - {\mu _i}} \right)\left( {{X_j} - {\mu _j}} \right)} \right]} }  = \sum\limits_{i = 1}^n {\sum\limits_{j = 1}^n {Cov\left( {{X_i},{X_j}} \right)} } $$<hr><p>看完上述xg1990大佬写的文章，整个人的心情瞬间舒畅，大佬文尾贴心地总结了Kriging模型建模步骤(如下图)。<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/kriging模型求解步骤.png" alt="kriging模型求解步骤"></p><p>于是我们就兴致冲冲开干，拿着dace工具箱想验算几篇论文。这里我们挑选两篇比较经典和较新的文章。<br>第一篇，韩忠华老师的文章<sup><a href="#fn_4" id="reffn_4">4</a></sup>。<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/韩忠华老师_kriging.png" alt="韩忠华老师文章"><br>什么? y(x)可以被表述成下式:</p><script type="math/tex; mode=display">y\left( x \right) = {\beta _0} + z\left( x \right)</script><p>$z(x)$竟然还是一个静态随机过程！</p><p>最后预测值竟然是:</p><script type="math/tex; mode=display">\hat y\left( x \right) = {\beta _0} + {r^T}\left( x \right){R^{ - 1} }\left( { {y_s} - {\beta _0}F} \right)</script><p>我们的$\hat y\left( x \right) = \sum\limits_{i = 1}^n { {\omega _i}{y_i} }$这样通俗易懂的插值到哪里去了啊？<br>在xg1990大佬博客中那个半方差函数又去哪了呢？怎么又多出来个相关函数$R\left( {\theta ,{x_i},{x_j} } \right)$呢？</p><p>于是我们又点开一篇文章。<br>第二篇，查从燚老师(or学长)文章<sup><a href="#fn_6" id="reffn_6">6</a></sup>。<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/查从燚_kriging.png" alt="查从燚_kriging"><br>kriging 模型又被表示成:</p><script type="math/tex; mode=display">\hat y\left( x \right) = {f^T}\left( x \right)\beta  + z\left( x \right)</script><p>怎么回事，怎么又多了个f(x)啊？把人搞得晕头转向！<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/小老弟你怎么回事.png" alt="小老弟你怎么回事"></p><p>莫慌莫慌，接下来我会带你捋一遍！发车咯(●ˇ∀ˇ●)</p><h1 id="Kriging-模型推导"><a href="#Kriging-模型推导" class="headerlink" title="Kriging 模型推导"></a>Kriging 模型推导</h1><p>Kriging模型一种插值模型，其插值结果定义为已知样本函数响应值的线性加权，即</p><script type="math/tex; mode=display">\hat y\left( x \right) = \sum\limits_{i = 1}^m { {\omega _i}{y_i} }</script><p>其中$\omega _i$就是待求的权重系数，x是一个n维向量，n是输入参数个数。<br>为了计算这个加权系数，Kriging模型引入统计学假设：将未知函数看成是一个回归模型和一个随机过程构成，数学表达式如下：<br>$$\hat y\left( x \right) = {f^T}\left( x \right)\beta  + z\left( x \right) = \sum\limits_{i = 1}^p {({f_i}\left( x \right)}  \times {\beta _i}) + z\left( x \right)$$<br>其中，$f_i(x)$称为x的基函数(一般为多项式)，${\beta}_i$称为x的回归模型系数，${f^T}\left( x \right)\beta$称为回归模型。</p><blockquote><p>此处f(x)的具体表达式是啥呢？<br>见下图。<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/基函数表达式.png" alt="f(x)表达式"><br>从上图我们就可以知道，$f_i(x)$有三种形式，分别对应于回归模型为常数(constant)、线性(linear)和二次项(quadratic)的情况。n为输入参数的个数。<br>噢噢，原来韩忠华老师那篇文章讲的是对应f(x)为常数的时候啊！同理，xg1990大佬那篇文章讲的也是f(x)为常数的情况！</p></blockquote><p>z(x)是一个均值为0，方差为$\sigma^2$的随机过程，其协方差满足：</p><script type="math/tex; mode=display">Cov\left( { {z_i},{z_j} } \right) = {\sigma ^2}R\left( \theta,{ {x_i},{x_j} } \right)</script><p>上式中$R\left( {\theta ,{x_i},{x_j} } \right)$称为<strong>相关函数</strong>，其只与空间距离有关(θ值一定时)，距离为0时，其值为1，距离为无穷大时，其值为0，也就是说相关性随着距离增大而减小。</p><blockquote><p>可能又有人要问了，这个相关函数是啥？<br>这里我们类比xg1990大佬提到的半方差函数，最后不是要得到$r = r\left( d \right)$嘛，也是与距离相关，故暂且认为相关函数充当了$r = r\left( d \right)$的作用！<br>对于这个相关函数的具体表达式，可见后面！</p></blockquote><p>对于Kriging模型，权重系数$\omega _i$的取值直接影响到模型的精度，因此我们关注的重点是最优的权重系数$\omega _i$如何得到。要取得最优权重系数$\omega _i$，需要满足如下两个条件：</p><ol><li>预测值满足无偏估计，$E\left( {\hat y\left( x \right)} \right) = y\left( x \right) = E\left( {y\left( x \right) } \right)$，即<br><script type="math/tex">E\left( {\hat y\left( x \right)-y\left( x \right) } \right) = 0</script>.</li><li>预测值的均方差(MSE)最小，即   $$\min E\left[ {{{\left( {\hat y\left( x \right) - y\left( x \right)} \right)}^2}} \right]$$   </li></ol><p>先定义一些后续推导需要用到的矩阵和向量。<br>基函数矩阵：<br>$$F = {\left[ {f^T\left( {{x_1}} \right),f^T\left( {{x_2}} \right),...,f^T\left( {{x_m}} \right)} \right]^T}$$$$f\left( {{x_i}} \right) = \left[ {{f_1}\left( {{x_i}} \right),{f_2}\left( {{x_i}} \right),...,{f_p}\left( {{x_i}} \right)} \right]^T  (i = 1,2,...,m)$$  </p><blockquote><p>这里m对应是m个样本点，p是一个样本点包含基函数的个数，$x_i$是一个向量。<br>以p=n+1为例，$f_1\left( x_i \right) = 1$, $f_2\left( x_i \right) = x_{i,1}$,…,$f_i^p\left( x \right) = x_{i,n}$.(i = 1,2,…,m)</p></blockquote><p>回归模型系数向量：</p><script type="math/tex; mode=display">\beta  = {\left[ { {\beta _1},{\beta _2},...,{\beta _p} } \right]^T}</script><p>随机过程向量：</p><script type="math/tex; mode=display">Z = {\left[ {z\left( { {x_1}} \right),z\left( { {x_2} } \right),...,z\left( { {x_m} } \right) } \right]^T}</script><p>权重系数向量：</p><script type="math/tex; mode=display">\omega  = {\left( { {\omega _1},{\omega _2},....,{\omega _m} } \right)^T}</script><p>响应值向量：</p><script type="math/tex; mode=display">{y_s} = {\left( { {y_1},{y_2},...,{y_m} } \right)^T}</script><p>相关矩阵：<br>$$R=\begin{bmatrix}R(\theta,x_1,x_1)&...&R(\theta,x_1,x_m)\\...&&...\\R(\theta,x_m,x_1)&...&R(\theta,x_m,x_m)\end{bmatrix}$$</p><p>相关向量：<br>$${r_x} = \left[ {R\left( {\theta ,{x_1},x} \right),R\left( {\theta ,{x_2},x} \right),...,R\left( {\theta ,{x_m},x} \right)} \right]^T$$</p><p>根据条件(1)，有<br>$$\begin{align*}E\left( {\hat y\left( x \right) - y\left( x \right)} \right) &= E\left[ {{\omega ^T}{y_s} - {f^T}\left( x \right)\beta  - z} \right] = E\left[ {{\omega ^T}\left( {F\beta  + Z} \right) - {f^T}\left( x \right)\beta  - z} \right] \\&= E\left[ {{\omega ^T}Z - z + {\omega ^T}F\beta  - {f^T}\left( x \right)\beta } \right] \\&= 0\end{align*}$$</p><p>由于$E\left( z \right) = 0$，故可得${\omega ^T}F - {f^T}\left( x \right) = 0$，等式两边同时转置，得</p><script type="math/tex; mode=display">\begin{equation} {F^T}\omega  - f\left( x \right) = 0\end{equation}</script><p>根据条件(2)，有<br>$$\begin{align*} E\left[ {{{\left( {\hat y\left( x \right) - y\left( x \right)} \right)}^2}} \right] &=  E\left[ {{{\left( {{\omega ^T}Z - z} \right)}^2}} \right] \\&= E\left[ {{{\left( {{z^2} + {\omega ^T}Z{Z^T}\omega } \right)}^2} - 2{\omega ^T}Zz} \right] \\&=  {\sigma ^2}\left( {1 + {\omega ^T}R\omega  - 2{\omega ^T}r} \right)\end{align*}$$</p><p>要求：</p><script type="math/tex; mode=display">\begin{equation} \min \{ {\sigma ^2}\left( {1 + {\omega ^T}R\omega  - 2{\omega ^T}r} \right)\}\end{equation}</script><p>要求Kriging模型的系数$\omega_i$，就必须同时满足式(1)和(2)。很容易就想到利用拉格朗日乘数法，构造如下拉格朗日函数：<br>$$L\left( {\omega ,\lambda } \right) = {\sigma ^2}\left( {1 + {\omega ^T}R\omega  - 2{\omega ^T}r} \right) - \lambda \left( {{F^T}\omega  - f\left( x \right)} \right)$$</p><p>对$\omega$和$\lambda$分别求偏导，得</p><script type="math/tex; mode=display">\frac{ {\partial L} } { {\partial \omega } } = 0 \Rightarrow 2{\sigma ^2}\left( {R\omega  - r} \right) - F\lambda  = 0</script><script type="math/tex; mode=display">\frac{ {\partial L} } { {\partial \lambda } } = 0 \Rightarrow {F^T}\omega  - f\left( x \right) = 0</script><p>解上述两式，得</p><script type="math/tex; mode=display">\lambda = - 2 \sigma ^ { 2 } ( F ^ { T } R ^ { - 1 } F ) ^ { - 1 } ( F ^ { T } R ^ { - 1 } r  - f(x) )</script><script type="math/tex; mode=display">\omega = R ^ { - 1 } ( r  - F ( F ^ { T } R ^ { - 1 } F ) ^ { - 1 } ( F ^ { T } R ^ { - 1 } r  - f (x) ) )</script><p>再回代进$\hat y = {\omega ^T} {y_s}$，有</p><script type="math/tex; mode=display">\begin{equation} \hat { y } ( x ) = \omega ^ { T } y _ { s } = r  ^ { T } R ^ { - 1 } y _ { s } - ( F ^ { T } R ^ { - 1 } r - f(x) ) ^ { T } ( F ^ { T } R ^ { - 1 } F ) ^ { - 1 } F ^ { T } R ^ { - 1 } y _ { s }\end{equation}</script><p>这里先给出$\beta$的最小二乘估计(证明后续给出)：</p><script type="math/tex; mode=display">\hat { \beta } = \left( F ^ { T } R ^ { - 1 } F \right) ^ { - 1 } F ^ { T } R ^ { - 1 } y _ { s }</script><blockquote><p>最小二乘估计属于最大似然估计的一种形式<sup><a href="#fn_8" id="reffn_8">8</a></sup>，最大似然估计是指在给定样本的情况下，得到某参数满足该样本出现概率最大的值，该值也称为该参数的最大似然估计值。</p></blockquote><p>这样，式(3)就可以被表示为</p><script type="math/tex; mode=display">\begin{equation} \hat y\left( x \right) = {f^T}\left( x \right)\hat \beta  + {r^T}{R^{ - 1} }\left( { {y_s} - F\hat \beta } \right)\end{equation}</script><p>通过式(4)就可以得到Kriging模型在未知点$x$的预测值了！</p><p>但是对于式(4)还有个问题，就是相关函数R中存在未知参数$\theta$，所以先要根据已知样本得到$\theta$的值，很显然需要通过最大似然估计来实现。</p><p>在介绍$\theta$的最大似然估计之前，先介绍相关函数R.</p><h1 id="相关函数R"><a href="#相关函数R" class="headerlink" title="相关函数R"></a>相关函数R</h1><p>相关函数R可以表示成如下式子：</p><script type="math/tex; mode=display">R\left( {\theta ,{x_i},{x_j} } \right) = \prod\limits_{k = 1}^n { {R_k}\left( {\theta ,x_i^k,x_j^k} \right) }</script><p>对于${ {R_k}\left( {\theta ,x_i^k,x_j^k} \right) }$，其具体表达式有如下几种：</p>$$\begin{array}{|c|c|}\hline{函数名} & { {{R_k}\left( {\theta ,x_i^k,x_j^k} \right) } }\\\hline{EXP} & { \exp \left( { - {\theta _k}\left| {x_i^k - x_j^k} \right|} \right) }   \\\hline{EXPG} & { \exp \left( { - {\theta _k}{{\left| {x_i^k - x_j^k} \right|}^{{\theta _{n + 1}}}}} \right),0 < {\theta _{n + 1}} \le 2 }  \\\hline{GAUSS} & { \exp \left( { - {\theta _k}{{\left| {x_i^k - x_j^k} \right|}^2}} \right) }   \\\hline{LIN} & {\max \left\{ {0,1 - {\theta _k}\left| {x_i^k - x_j^k} \right|} \right\} }   \\\hline{SPHERICAL} & { 1 - 1.5{\xi _k} + 0.5\xi _k^3,{\xi _k} = \min \left\{ {1,{\theta _k}\left| {x_i^k - x_j^k} \right|} \right\} }  \\\hline{CUBIC} & {1 - 3{\xi _k} + 2\xi _k^3,{\xi _k} = \min \left\{ {1,{\theta _k}\left| {x_i^k - x_j^k} \right|} \right\}}  \\\hline{SPLINE} & {\varsigma \left( {\xi _k} \right) , {\xi _k} = {\theta _k}\left| {x_i^k - x_j^k} \right|}  \\\hline\end{array}$$$$\varsigma \left( {{\xi _k}} \right) = \left\{ \begin{array}{l}1 - 15\xi _k^2 + 30\xi _k^3,0 \le {\xi _k} \le 0.2\\1.25{\left( {1 - {\xi _k}} \right)^3},0.2 < {\xi _k} < 1\\0,{\xi _k} \ge 1\end{array} \right.$$<h1 id="theta-的最大似然估计值"><a href="#theta-的最大似然估计值" class="headerlink" title="$\theta$的最大似然估计值"></a>$\theta$的最大似然估计值</h1><p>我已经懒得敲公式了，基本思路就是刘俊老师的博士论文<sup><a href="#fn_7" id="reffn_7">7</a></sup>所写的，这里贴出我论文中写的：<br><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/θ的最大似然估计-1.png" alt="θ的最大似然估计值"></p><p><img src="/2025/06Kriging%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/θ的最大似然估计-2.png" alt="θ的最大似然估计值-2"></p><blockquote><p>式(3.20)就是本文中式(4)!</p></blockquote><hr><p>到这里，Kriging模型的推导大致就结束啦！<strong>从上面推导可以看出，Kriging模型就是根据无偏估计和均方差最小两个条件得到的，但此时还有参数未确定，在给定样本情况下推参数，采用最大似然估计</strong>。</p><p>其实上述推导大多内容都来自前面dace工具箱所带的说明书，所以说学好英语很重要哈哈！</p><p>推导完Kriging模型，感觉影响其精度最重要的参数无非就是相关函数R的选取以及后面参数$\theta$的估计值，这也体现在dace工具箱的运用上！也有老师做过相关研究，利用一些算法寻找最优$\theta$值。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><blockquote id="fn_1"><sup>1</sup>. <a href="https://www.bilibili.com/video/BV1Xr4y147nu/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&amp;vd_source=41769b252ab81d02e47e5775242eda15">https://www.bilibili.com/video/BV1Xr4y147nu/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&amp;vd_source=41769b252ab81d02e47e5775242eda15</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a></blockquote><blockquote id="fn_2"><sup>2</sup>. <a href="https://www.omicron.dk/dace.html">https://www.omicron.dk/dace.html</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a></blockquote><blockquote id="fn_3"><sup>3</sup>. <a href="https://xg1990.com/blog/archives/222">https://xg1990.com/blog/archives/222</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a></blockquote><blockquote id="fn_4"><sup>4</sup>. 韩忠华. Kriging模型及代理优化算法研究进展[J]. 航空学报, 2016, 37(11): 3197-3225.<a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a></blockquote><blockquote id="fn_5"><sup>5</sup>. <a href="https://www.omicron.dk/dace/dace.pdf">https://www.omicron.dk/dace/dace.pdf</a><a href="#reffn_5" title="Jump back to footnote [5] in the text."> &#8617;</a></blockquote><blockquote id="fn_6"><sup>6</sup>. 查从燚,孙志礼,刘勤等.基于Kriging模型的液压管道防油击可靠性分析[J/OL].兵工学报:1-7[2024-03-23].<a href="#reffn_6" title="Jump back to footnote [6] in the text."> &#8617;</a></blockquote><blockquote id="fn_7"><sup>7</sup>. 刘俊. 基于代理模型的高效气动优化设计方法及应用[D]. 西北工业大学, 2017.<a href="#reffn_7" title="Jump back to footnote [7] in the text."> &#8617;</a></blockquote><blockquote id="fn_8"><sup>8</sup>. <a href="https://www.bilibili.com/video/BV1QM4y167oZ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=41769b252ab81d02e47e5775242eda15">https://www.bilibili.com/video/BV1QM4y167oZ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=41769b252ab81d02e47e5775242eda15</a><a href="#reffn_8" title="Jump back to footnote [8] in the text."> &#8617;</a></blockquote>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
